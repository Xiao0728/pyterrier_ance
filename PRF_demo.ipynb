{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "controlled-superintendent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jan 23 13:51:32 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.74       Driver Version: 470.74       CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA TITAN RTX    Off  | 00000000:1A:00.0 Off |                  N/A |\r\n",
      "| 40%   54C    P2    64W / 280W |   2966MiB / 24220MiB |     11%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "formal-strand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aboriginal-unknown",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.9.2 has loaded Terrier 5.7 (built by craigm on 2022-11-10 18:30) and terrier-helper 0.0.7\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    }
   ],
   "source": [
    "import pyterrier as pt\n",
    "# pt.init(tqdm='notebook')\n",
    "pt.init(boot_packages=[\"com.github.terrierteam:terrier-prf:-SNAPSHOT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "integral-voltage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import faiss\n",
    "faiss.get_num_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "interpreted-child",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "qrels2019 = pt.get_dataset(\"trec-deep-learning-passages\").get_qrels('test-2019')\n",
    "topics2019 = pt.get_dataset(\"trec-deep-learning-passages\").get_topics('test-2019')\n",
    "topics2019 = topics2019.merge(qrels2019[qrels2019[\"label\"] > 0][[\"qid\"]].drop_duplicates())\n",
    "\n",
    "\n",
    "\n",
    "topics2020 = pt.get_dataset(\"trec-deep-learning-passages\").get_topics('test-2020')\n",
    "qrels2020 = pt.get_dataset(  \"trec-deep-learning-passages\").get_qrels('test-2020')\n",
    "topics2020 = topics2020.merge(qrels2020[qrels2020[\"label\"] > 0][[\"qid\"]].drop_duplicates())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-eagle",
   "metadata": {},
   "source": [
    "# ANCE-PRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "portuguese-challenge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint /nfs/craigm/Passage ANCE(FirstP) Checkpoint\n",
      "Using mean: False\n",
      "Loading shard metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading shards: 100%|██████████| 18/18 [00:19<00:00,  1.10s/shard]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint ./k3_checkpoint\n",
      "Using mean: False\n",
      "Loading checkpoint /nfs/craigm/Passage ANCE(FirstP) Checkpoint\n",
      "Using mean: False\n",
      "Loading shard metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading shards: 100%|██████████| 18/18 [00:18<00:00,  1.05s/shard]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pyterrier_ance\n",
    "# build the ANCE retriever\n",
    "anceRetr = pyterrier_ance.ANCERetrieval(\"/nfs/craigm/Passage ANCE(FirstP) Checkpoint\", \n",
    "                                        \"/nfs/craigm/ance_msmarco_passages/\",num_results=2000)\n",
    "# load the ANCE-PRF k=3 checkpoint\n",
    "anceprf = pyterrier_ance.ANCEPRF(checkpoint_path=\"./k3_checkpoint\")\n",
    "# # retrieval using the refined query rerpesentation using ANCE\n",
    "anceRetr_prf = pyterrier_ance.ANCERetrieval( \"/nfs/craigm/Passage ANCE(FirstP) Checkpoint\",\"/nfs/craigm/ance_msmarco_passages/\", query_encoded=True,num_results=2000,index_on_gpu=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "solved-joshua",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_anceprf =anceRetr%10>>pt.text.get_text(pt.get_dataset('irds:msmarco-passage'), 'text')>>anceprf>>anceRetr_prf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "super-divorce",
   "metadata": {},
   "source": [
    "# Vector-PRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "tracked-attribute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint /nfs/craigm/Passage ANCE(FirstP) Checkpoint\n",
      "Using mean: False\n",
      "Loading checkpoint /nfs/craigm/Passage ANCE(FirstP) Checkpoint\n",
      "Using mean: False\n"
     ]
    }
   ],
   "source": [
    "qencoder= pyterrier_ance.ANCEQueryEncoder(checkpoint_path=\"/nfs/craigm/Passage ANCE(FirstP) Checkpoint\")\n",
    "dencoder = pyterrier_ance.ANCETextEncoder(checkpoint_path=\"/nfs/craigm/Passage ANCE(FirstP) Checkpoint\")\n",
    "vectorprf = pyterrier_ance.PRF_VectorAverage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "clinical-fetish",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_vectorprf = (anceRetr%10\n",
    "        >>qencoder\n",
    "        >>pt.text.get_text(pt.get_dataset('irds:msmarco-passage'), 'text')\n",
    "        >>dencoder>>pyterrier_ance.PRF_VectorAverage(k=3,prf_type = \"vector_prf\")\n",
    "        >>anceRetr_prf\n",
    "        \n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cloudy-mississippi",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rocchioprf = (anceRetr%10\n",
    "        >>qencoder\n",
    "        >>pt.text.get_text(pt.get_dataset('irds:msmarco-passage'), 'text')\n",
    "        >>dencoder>>pyterrier_ance.PRF_VectorAverage(k=3,alpha=0.4,beta=0.6,prf_type = \"rocchio_prf\")\n",
    "        >>anceRetr_prf\n",
    "        \n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "alone-pencil",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pt.Experiment:  10%|█         | 2/20 [00:00<00:06,  2.82batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** inference of 10 queries *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing: 1it [00:00, 21.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running in distributed mode\n",
      "***** faiss search for 10 queries on 18 shards *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/18 [00:00<?, ?shard/s]\u001b[A\n",
      "  6%|▌         | 1/18 [00:02<00:37,  2.22s/shard]\u001b[A\n",
      " 11%|█         | 2/18 [00:04<00:34,  2.14s/shard]\u001b[A\n",
      " 17%|█▋        | 3/18 [00:06<00:33,  2.22s/shard]\u001b[A\n",
      " 22%|██▏       | 4/18 [00:09<00:34,  2.48s/shard]\u001b[A\n",
      " 28%|██▊       | 5/18 [00:11<00:31,  2.41s/shard]\u001b[A\n",
      " 33%|███▎      | 6/18 [00:13<00:27,  2.29s/shard]\u001b[A\n",
      " 39%|███▉      | 7/18 [00:16<00:25,  2.28s/shard]\u001b[A\n",
      " 44%|████▍     | 8/18 [00:18<00:22,  2.26s/shard]\u001b[A\n",
      " 50%|█████     | 9/18 [00:20<00:21,  2.38s/shard]\u001b[A\n",
      " 56%|█████▌    | 10/18 [00:23<00:18,  2.34s/shard]\u001b[A\n",
      " 61%|██████    | 11/18 [00:25<00:16,  2.29s/shard]\u001b[A\n",
      " 67%|██████▋   | 12/18 [00:27<00:13,  2.29s/shard]\u001b[A\n",
      " 72%|███████▏  | 13/18 [00:29<00:11,  2.27s/shard]\u001b[A\n",
      " 78%|███████▊  | 14/18 [00:32<00:09,  2.40s/shard]\u001b[A\n",
      " 83%|████████▎ | 15/18 [00:34<00:06,  2.30s/shard]\u001b[A\n",
      " 89%|████████▉ | 16/18 [00:36<00:04,  2.25s/shard]\u001b[A\n",
      " 94%|█████████▍| 17/18 [00:38<00:02,  2.23s/shard]\u001b[A\n",
      "100%|██████████| 18/18 [00:40<00:00,  2.25s/shard]\u001b[A\n",
      "Inferencing: 1it [00:00, 21.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running in distributed mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Inferencing: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running in distributed mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing: 1it [00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** faiss search for 10 queries on 18 shards *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/18 [00:00<?, ?shard/s]\u001b[A\n",
      "  6%|▌         | 1/18 [00:02<00:48,  2.84s/shard]\u001b[A\n",
      " 11%|█         | 2/18 [00:04<00:38,  2.41s/shard]\u001b[A\n",
      " 17%|█▋        | 3/18 [00:07<00:33,  2.26s/shard]\u001b[A\n",
      " 22%|██▏       | 4/18 [00:09<00:30,  2.21s/shard]\u001b[A\n",
      " 28%|██▊       | 5/18 [00:11<00:28,  2.16s/shard]\u001b[A\n",
      " 33%|███▎      | 6/18 [00:13<00:27,  2.31s/shard]\u001b[A\n",
      " 39%|███▉      | 7/18 [00:15<00:23,  2.18s/shard]\u001b[A\n",
      " 44%|████▍     | 8/18 [00:17<00:21,  2.16s/shard]\u001b[A\n",
      " 50%|█████     | 9/18 [00:19<00:18,  2.09s/shard]\u001b[A\n",
      " 56%|█████▌    | 10/18 [00:21<00:16,  2.04s/shard]\u001b[A\n",
      " 61%|██████    | 11/18 [00:24<00:15,  2.25s/shard]\u001b[A\n",
      " 67%|██████▋   | 12/18 [00:26<00:13,  2.18s/shard]\u001b[A\n",
      " 72%|███████▏  | 13/18 [00:28<00:10,  2.15s/shard]\u001b[A\n",
      " 78%|███████▊  | 14/18 [00:30<00:08,  2.08s/shard]\u001b[A\n",
      " 83%|████████▎ | 15/18 [00:32<00:06,  2.09s/shard]\u001b[A\n",
      " 89%|████████▉ | 16/18 [00:34<00:04,  2.17s/shard]\u001b[A\n",
      " 94%|█████████▍| 17/18 [00:37<00:02,  2.19s/shard]\u001b[A\n",
      "100%|██████████| 18/18 [00:38<00:00,  2.15s/shard]\u001b[A\n",
      "pt.Experiment:  15%|█▌        | 3/20 [01:21<10:30, 37.11s/batches]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** inference of 10 queries *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing: 1it [00:00, 21.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running in distributed mode\n",
      "***** faiss search for 10 queries on 18 shards *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/18 [00:00<?, ?shard/s]\u001b[A\n",
      "  6%|▌         | 1/18 [00:02<00:36,  2.16s/shard]\u001b[A\n",
      " 11%|█         | 2/18 [00:04<00:36,  2.29s/shard]\u001b[A\n",
      " 17%|█▋        | 3/18 [00:06<00:32,  2.20s/shard]\u001b[A\n",
      " 22%|██▏       | 4/18 [00:08<00:30,  2.18s/shard]\u001b[A\n",
      " 28%|██▊       | 5/18 [00:10<00:27,  2.15s/shard]\u001b[A\n",
      " 33%|███▎      | 6/18 [00:12<00:25,  2.09s/shard]\u001b[A\n",
      " 39%|███▉      | 7/18 [00:15<00:23,  2.17s/shard]\u001b[A\n",
      " 44%|████▍     | 8/18 [00:17<00:21,  2.17s/shard]\u001b[A\n",
      " 50%|█████     | 9/18 [00:19<00:19,  2.15s/shard]\u001b[A\n",
      " 56%|█████▌    | 10/18 [00:21<00:17,  2.14s/shard]\u001b[A\n",
      " 61%|██████    | 11/18 [00:23<00:14,  2.09s/shard]\u001b[A\n",
      " 67%|██████▋   | 12/18 [00:26<00:13,  2.32s/shard]\u001b[A\n",
      " 72%|███████▏  | 13/18 [00:29<00:12,  2.53s/shard]\u001b[A\n",
      " 78%|███████▊  | 14/18 [00:31<00:09,  2.38s/shard]\u001b[A\n",
      " 83%|████████▎ | 15/18 [00:33<00:06,  2.25s/shard]\u001b[A\n",
      " 89%|████████▉ | 16/18 [00:35<00:04,  2.22s/shard]\u001b[A\n",
      " 94%|█████████▍| 17/18 [00:38<00:02,  2.34s/shard]\u001b[A\n",
      "100%|██████████| 18/18 [00:39<00:00,  2.21s/shard]\u001b[A\n",
      "Inferencing: 1it [00:00, 20.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running in distributed mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Inferencing: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running in distributed mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing: 1it [00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** faiss search for 10 queries on 18 shards *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/18 [00:00<?, ?shard/s]\u001b[A\n",
      "  6%|▌         | 1/18 [00:02<00:36,  2.14s/shard]\u001b[A\n",
      " 11%|█         | 2/18 [00:04<00:32,  2.06s/shard]\u001b[A\n",
      " 17%|█▋        | 3/18 [00:06<00:30,  2.05s/shard]\u001b[A\n",
      " 22%|██▏       | 4/18 [00:08<00:32,  2.34s/shard]\u001b[A\n",
      " 28%|██▊       | 5/18 [00:10<00:28,  2.21s/shard]\u001b[A\n",
      " 33%|███▎      | 6/18 [00:12<00:25,  2.14s/shard]\u001b[A\n",
      " 39%|███▉      | 7/18 [00:15<00:23,  2.16s/shard]\u001b[A\n",
      " 44%|████▍     | 8/18 [00:17<00:22,  2.27s/shard]\u001b[A\n",
      " 50%|█████     | 9/18 [00:19<00:19,  2.20s/shard]\u001b[A\n",
      " 56%|█████▌    | 10/18 [00:21<00:17,  2.17s/shard]\u001b[A\n",
      " 61%|██████    | 11/18 [00:23<00:15,  2.15s/shard]\u001b[A\n",
      " 67%|██████▋   | 12/18 [00:26<00:12,  2.15s/shard]\u001b[A\n",
      " 72%|███████▏  | 13/18 [00:28<00:11,  2.31s/shard]\u001b[A\n",
      " 78%|███████▊  | 14/18 [00:30<00:09,  2.28s/shard]\u001b[A\n",
      " 83%|████████▎ | 15/18 [00:33<00:06,  2.33s/shard]\u001b[A\n",
      " 89%|████████▉ | 16/18 [00:35<00:04,  2.35s/shard]\u001b[A\n",
      " 94%|█████████▍| 17/18 [00:38<00:02,  2.38s/shard]\u001b[A\n",
      "100%|██████████| 18/18 [00:41<00:00,  2.31s/shard]\u001b[A\n",
      "pt.Experiment:  20%|██        | 4/20 [02:44<14:41, 55.06s/batches]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** inference of 10 queries *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing: 1it [00:00, 21.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running in distributed mode\n",
      "***** faiss search for 10 queries on 18 shards *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/18 [00:00<?, ?shard/s]\u001b[A\n",
      "  6%|▌         | 1/18 [00:02<00:40,  2.38s/shard]\u001b[A\n",
      " 11%|█         | 2/18 [00:04<00:36,  2.28s/shard]\u001b[A\n",
      " 17%|█▋        | 3/18 [00:06<00:35,  2.34s/shard]\u001b[A\n",
      " 22%|██▏       | 4/18 [00:09<00:33,  2.39s/shard]\u001b[A\n",
      " 28%|██▊       | 5/18 [00:12<00:32,  2.52s/shard]\u001b[A\n",
      " 33%|███▎      | 6/18 [00:14<00:29,  2.50s/shard]\u001b[A\n",
      " 39%|███▉      | 7/18 [00:16<00:26,  2.43s/shard]\u001b[A\n",
      " 44%|████▍     | 8/18 [00:19<00:24,  2.43s/shard]\u001b[A\n",
      " 50%|█████     | 9/18 [00:22<00:23,  2.61s/shard]\u001b[A\n",
      " 56%|█████▌    | 10/18 [00:24<00:20,  2.53s/shard]\u001b[A\n",
      " 61%|██████    | 11/18 [00:27<00:17,  2.50s/shard]\u001b[A\n",
      " 67%|██████▋   | 12/18 [00:29<00:14,  2.45s/shard]\u001b[A\n",
      " 72%|███████▏  | 13/18 [00:32<00:12,  2.49s/shard]\u001b[A\n",
      " 78%|███████▊  | 14/18 [00:35<00:10,  2.69s/shard]\u001b[A\n",
      " 83%|████████▎ | 15/18 [00:37<00:07,  2.58s/shard]\u001b[A\n",
      " 89%|████████▉ | 16/18 [00:40<00:05,  2.56s/shard]\u001b[A\n",
      " 94%|█████████▍| 17/18 [00:42<00:02,  2.52s/shard]\u001b[A\n",
      "100%|██████████| 18/18 [00:44<00:00,  2.45s/shard]\u001b[A\n",
      "Inferencing: 1it [00:00, 21.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running in distributed mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Inferencing: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running in distributed mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing: 1it [00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** faiss search for 10 queries on 18 shards *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/18 [00:00<?, ?shard/s]\u001b[A\n",
      "  6%|▌         | 1/18 [00:02<00:49,  2.89s/shard]\u001b[A\n",
      " 11%|█         | 2/18 [00:05<00:42,  2.64s/shard]\u001b[A\n",
      " 17%|█▋        | 3/18 [00:07<00:37,  2.52s/shard]\u001b[A\n",
      " 22%|██▏       | 4/18 [00:10<00:34,  2.48s/shard]\u001b[A\n",
      " 28%|██▊       | 5/18 [00:12<00:32,  2.48s/shard]\u001b[A\n",
      " 33%|███▎      | 6/18 [00:15<00:32,  2.67s/shard]\u001b[A\n",
      " 39%|███▉      | 7/18 [00:18<00:28,  2.58s/shard]\u001b[A\n",
      " 44%|████▍     | 8/18 [00:20<00:25,  2.54s/shard]\u001b[A\n",
      " 50%|█████     | 9/18 [00:23<00:22,  2.54s/shard]\u001b[A\n",
      " 56%|█████▌    | 10/18 [00:25<00:19,  2.49s/shard]\u001b[A\n",
      " 61%|██████    | 11/18 [00:28<00:18,  2.59s/shard]\u001b[A\n",
      " 67%|██████▋   | 12/18 [00:30<00:15,  2.53s/shard]\u001b[A\n",
      " 72%|███████▏  | 13/18 [00:33<00:12,  2.49s/shard]\u001b[A\n",
      " 78%|███████▊  | 14/18 [00:35<00:09,  2.49s/shard]\u001b[A\n",
      " 83%|████████▎ | 15/18 [00:38<00:07,  2.59s/shard]\u001b[A\n",
      " 89%|████████▉ | 16/18 [00:40<00:05,  2.54s/shard]\u001b[A\n",
      " 94%|█████████▍| 17/18 [00:43<00:02,  2.49s/shard]\u001b[A\n",
      "100%|██████████| 18/18 [00:44<00:00,  2.50s/shard]\u001b[A\n",
      "pt.Experiment:  25%|██▌       | 5/20 [04:15<17:00, 68.05s/batches]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** inference of 10 queries *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing: 1it [00:00, 21.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running in distributed mode\n",
      "***** faiss search for 10 queries on 18 shards *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/18 [00:00<?, ?shard/s]\u001b[A\n",
      "  6%|▌         | 1/18 [00:02<00:40,  2.39s/shard]\u001b[A\n",
      " 11%|█         | 2/18 [00:05<00:41,  2.60s/shard]\u001b[A\n",
      " 17%|█▋        | 3/18 [00:07<00:37,  2.49s/shard]\u001b[A\n",
      " 22%|██▏       | 4/18 [00:09<00:34,  2.46s/shard]\u001b[A\n",
      " 28%|██▊       | 5/18 [00:12<00:31,  2.45s/shard]\u001b[A\n",
      " 33%|███▎      | 6/18 [00:14<00:29,  2.45s/shard]\u001b[A\n",
      " 39%|███▉      | 7/18 [00:17<00:28,  2.63s/shard]\u001b[A\n",
      " 44%|████▍     | 8/18 [00:20<00:25,  2.52s/shard]\u001b[A\n",
      " 50%|█████     | 9/18 [00:22<00:22,  2.47s/shard]\u001b[A\n",
      " 56%|█████▌    | 10/18 [00:24<00:18,  2.35s/shard]\u001b[A\n",
      " 61%|██████    | 11/18 [00:26<00:15,  2.24s/shard]\u001b[A\n",
      " 67%|██████▋   | 12/18 [00:29<00:14,  2.34s/shard]\u001b[A\n",
      " 72%|███████▏  | 13/18 [00:31<00:11,  2.23s/shard]\u001b[A\n",
      " 78%|███████▊  | 14/18 [00:33<00:08,  2.17s/shard]\u001b[A\n",
      " 83%|████████▎ | 15/18 [00:35<00:06,  2.13s/shard]\u001b[A\n",
      " 89%|████████▉ | 16/18 [00:37<00:04,  2.25s/shard]\u001b[A\n",
      " 94%|█████████▍| 17/18 [00:39<00:02,  2.20s/shard]\u001b[A\n",
      "100%|██████████| 18/18 [00:41<00:00,  2.29s/shard]\u001b[A\n",
      "Inferencing: 1it [00:00, 20.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running in distributed mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Inferencing: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running in distributed mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing: 1it [00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** faiss search for 10 queries on 18 shards *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/18 [00:00<?, ?shard/s]\u001b[A\n",
      "  6%|▌         | 1/18 [00:02<00:36,  2.14s/shard]\u001b[A\n",
      " 11%|█         | 2/18 [00:04<00:33,  2.10s/shard]\u001b[A\n",
      " 17%|█▋        | 3/18 [00:06<00:33,  2.25s/shard]\u001b[A\n",
      " 22%|██▏       | 4/18 [00:08<00:30,  2.21s/shard]\u001b[A\n",
      " 28%|██▊       | 5/18 [00:10<00:28,  2.16s/shard]\u001b[A\n",
      " 33%|███▎      | 6/18 [00:12<00:25,  2.15s/shard]\u001b[A\n",
      " 39%|███▉      | 7/18 [00:14<00:23,  2.09s/shard]\u001b[A\n",
      " 44%|████▍     | 8/18 [00:17<00:22,  2.24s/shard]\u001b[A\n",
      " 50%|█████     | 9/18 [00:19<00:19,  2.19s/shard]\u001b[A\n",
      " 56%|█████▌    | 10/18 [00:21<00:16,  2.10s/shard]\u001b[A\n",
      " 61%|██████    | 11/18 [00:23<00:14,  2.06s/shard]\u001b[A\n",
      " 67%|██████▋   | 12/18 [00:25<00:12,  2.07s/shard]\u001b[A\n",
      " 72%|███████▏  | 13/18 [00:28<00:11,  2.20s/shard]\u001b[A\n",
      " 78%|███████▊  | 14/18 [00:30<00:08,  2.15s/shard]\u001b[A\n",
      " 83%|████████▎ | 15/18 [00:32<00:06,  2.09s/shard]\u001b[A\n",
      " 89%|████████▉ | 16/18 [00:33<00:04,  2.04s/shard]\u001b[A\n",
      " 94%|█████████▍| 17/18 [00:36<00:02,  2.13s/shard]\u001b[A\n",
      "100%|██████████| 18/18 [00:37<00:00,  2.10s/shard]\u001b[A\n",
      "pt.Experiment:  30%|███       | 6/20 [05:35<16:51, 72.25s/batches]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** inference of 3 queries *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing: 1it [00:00, 30.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running in distributed mode\n",
      "***** faiss search for 3 queries on 18 shards *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/18 [00:00<?, ?shard/s]\u001b[A\n",
      "  6%|▌         | 1/18 [00:00<00:16,  1.05shard/s]\u001b[A\n",
      " 11%|█         | 2/18 [00:01<00:13,  1.22shard/s]\u001b[A\n",
      " 17%|█▋        | 3/18 [00:02<00:12,  1.23shard/s]\u001b[A\n",
      " 22%|██▏       | 4/18 [00:03<00:11,  1.24shard/s]\u001b[A\n",
      " 28%|██▊       | 5/18 [00:04<00:10,  1.24shard/s]\u001b[A\n",
      " 33%|███▎      | 6/18 [00:04<00:09,  1.24shard/s]\u001b[A\n",
      " 39%|███▉      | 7/18 [00:05<00:08,  1.24shard/s]\u001b[A\n",
      " 44%|████▍     | 8/18 [00:06<00:08,  1.24shard/s]\u001b[A\n",
      " 50%|█████     | 9/18 [00:07<00:07,  1.24shard/s]\u001b[A\n",
      " 56%|█████▌    | 10/18 [00:08<00:06,  1.24shard/s]\u001b[A\n",
      " 61%|██████    | 11/18 [00:08<00:05,  1.24shard/s]\u001b[A\n",
      " 67%|██████▋   | 12/18 [00:09<00:04,  1.24shard/s]\u001b[A\n",
      " 72%|███████▏  | 13/18 [00:10<00:04,  1.24shard/s]\u001b[A\n",
      " 78%|███████▊  | 14/18 [00:11<00:03,  1.24shard/s]\u001b[A\n",
      " 83%|████████▎ | 15/18 [00:12<00:02,  1.24shard/s]\u001b[A\n",
      " 89%|████████▉ | 16/18 [00:12<00:01,  1.24shard/s]\u001b[A\n",
      " 94%|█████████▍| 17/18 [00:13<00:00,  1.24shard/s]\u001b[A\n",
      "100%|██████████| 18/18 [00:14<00:00,  1.26shard/s]\u001b[A\n",
      "Inferencing: 1it [00:00, 82.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running in distributed mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing: 1it [00:00,  8.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running in distributed mode\n",
      "***** faiss search for 3 queries on 18 shards *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/18 [00:00<?, ?shard/s]\u001b[A\n",
      "  6%|▌         | 1/18 [00:00<00:13,  1.23shard/s]\u001b[A\n",
      " 11%|█         | 2/18 [00:01<00:12,  1.24shard/s]\u001b[A\n",
      " 17%|█▋        | 3/18 [00:02<00:15,  1.00s/shard]\u001b[A\n",
      " 22%|██▏       | 4/18 [00:03<00:12,  1.08shard/s]\u001b[A\n",
      " 28%|██▊       | 5/18 [00:04<00:11,  1.14shard/s]\u001b[A\n",
      " 33%|███▎      | 6/18 [00:05<00:10,  1.17shard/s]\u001b[A\n",
      " 39%|███▉      | 7/18 [00:06<00:09,  1.20shard/s]\u001b[A\n",
      " 44%|████▍     | 8/18 [00:06<00:08,  1.21shard/s]\u001b[A\n",
      " 50%|█████     | 9/18 [00:07<00:07,  1.18shard/s]\u001b[A\n",
      " 56%|█████▌    | 10/18 [00:08<00:06,  1.20shard/s]\u001b[A\n",
      " 61%|██████    | 11/18 [00:09<00:05,  1.20shard/s]\u001b[A\n",
      " 67%|██████▋   | 12/18 [00:10<00:04,  1.22shard/s]\u001b[A\n",
      " 72%|███████▏  | 13/18 [00:10<00:04,  1.23shard/s]\u001b[A\n",
      " 78%|███████▊  | 14/18 [00:11<00:03,  1.20shard/s]\u001b[A\n",
      " 83%|████████▎ | 15/18 [00:12<00:02,  1.21shard/s]\u001b[A\n",
      " 89%|████████▉ | 16/18 [00:13<00:01,  1.20shard/s]\u001b[A\n",
      " 94%|█████████▍| 17/18 [00:14<00:00,  1.13shard/s]\u001b[A\n",
      "100%|██████████| 18/18 [00:15<00:00,  1.19shard/s]\u001b[A\n",
      "pt.Experiment:  40%|████      | 8/20 [06:05<09:08, 45.73s/batches]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>AP(rel=2)@1000</th>\n",
       "      <th>nDCG@10</th>\n",
       "      <th>R(rel=2)@1000</th>\n",
       "      <th>mrt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ance.dl19</td>\n",
       "      <td>0.371512</td>\n",
       "      <td>0.653703</td>\n",
       "      <td>0.757131</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ance-prf.dl19</td>\n",
       "      <td>0.426855</td>\n",
       "      <td>0.677552</td>\n",
       "      <td>0.793970</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vector-prf.dl19</td>\n",
       "      <td>0.428616</td>\n",
       "      <td>0.662689</td>\n",
       "      <td>0.774935</td>\n",
       "      <td>8435.19527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rocchio-prf.dl19</td>\n",
       "      <td>0.421635</td>\n",
       "      <td>0.659355</td>\n",
       "      <td>0.774879</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name  AP(rel=2)@1000   nDCG@10  R(rel=2)@1000         mrt\n",
       "0         ance.dl19        0.371512  0.653703       0.757131     0.00000\n",
       "1     ance-prf.dl19        0.426855  0.677552       0.793970     0.00000\n",
       "2   vector-prf.dl19        0.428616  0.662689       0.774935  8435.19527\n",
       "3  rocchio-prf.dl19        0.421635  0.659355       0.774879     0.00000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from pyterrier.measures import *\n",
    "res = pt.Experiment(\n",
    "    [anceRetr, pipe_anceprf, pipe_vectorprf, pipe_rocchioprf\n",
    "    ],\n",
    "    topics2019,\n",
    "    qrels2019,\n",
    "    save_dir=\"./\",\n",
    "    eval_metrics=[AP(rel=2)@1000, nDCG@10,R(rel=2)@1000,\"mrt\"],\n",
    "#     baseline=0,\n",
    "    names=[\"ance.dl19\",\"ance-prf.dl19\",\"vector-prf.dl19\",'rocchio-prf.dl19'], verbose=True, batch_size=10,\n",
    ")\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-principle",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ance",
   "language": "python",
   "name": "ance"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
